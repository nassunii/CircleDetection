{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from thop import profile  # FLOPs 계산용\n",
    "\n",
    "# 기존 모델들 import\n",
    "from KD import TeacherNet, StudentNet \n",
    "from model import CircleNet, CircleDataset\n",
    "from pruning import CircleNet_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    # Basic 모델\n",
    "    basic_model = CircleNet()\n",
    "    basic_model.load_state_dict(torch.load('Basic_model.pth'))\n",
    "    \n",
    "    # Pruned 모델\n",
    "    pruned_model = CircleNet_P(pruning_ratio=0.5)\n",
    "    pruned_model.load_state_dict(torch.load('P_model.pth'))\n",
    "    \n",
    "    # KD 모델 (이전의 Quantized 모델 부분을 변경)\n",
    "    student_model = StudentNet()\n",
    "    student_model.load_state_dict(torch.load('KD_model.pth'))\n",
    "    \n",
    "    return basic_model, pruned_model, student_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_flops(model, input_size=(1, 1, 416, 416)):\n",
    "    \"\"\"모델의 FLOPs 계산\"\"\"\n",
    "    input = torch.randn(input_size)\n",
    "    flops, params = profile(model, inputs=(input, ))\n",
    "    return flops, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_model_metrics(model, test_loader, device, model_name):\n",
    "    \"\"\"모델의 모든 메트릭 측정\"\"\"\n",
    "    print(f\"\\nMeasuring metrics for {model_name}...\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 1. 모델 크기 및 파라미터\n",
    "    param_count = sum(p.numel() for p in model.parameters())\n",
    "    torch.save(model.state_dict(), 'temp.pth')\n",
    "    model_size = os.path.getsize('temp.pth') / (1024 * 1024)  # MB\n",
    "    os.remove('temp.pth')\n",
    "    \n",
    "    # 2. FLOPs 계산\n",
    "    try:\n",
    "        flops, _ = calculate_flops(model)\n",
    "    except Exception as e:\n",
    "        print(f\"FLOPs calculation failed: {e}\")\n",
    "        flops = 0\n",
    "    \n",
    "    # 3. 추론 성능 측정\n",
    "    model.eval()\n",
    "    inference_times = []\n",
    "    memory_usage = []\n",
    "    accuracy = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in test_loader:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # 메모리 사용량\n",
    "            memory_usage.append(psutil.Process().memory_info().rss / 1024**2)\n",
    "            \n",
    "            # 추론 시간\n",
    "            start_time = time.time()\n",
    "            outputs = model(images)\n",
    "            inference_times.append((time.time() - start_time) * 1000)\n",
    "            \n",
    "            # 정확도\n",
    "            pred = outputs.round()\n",
    "            acc = (torch.abs(pred - targets) <= 1).float().mean().item()\n",
    "            accuracy.append(acc)\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Parameters': param_count,\n",
    "        'Model_Size_MB': model_size,\n",
    "        'GFLOPs': flops / 1e9,\n",
    "        'Avg_Inference_Time_ms': np.mean(inference_times),\n",
    "        'Inference_Time_Std_ms': np.std(inference_times),\n",
    "        'Memory_Usage_MB': np.mean(memory_usage),\n",
    "        'Accuracy_%': np.mean(accuracy) * 100\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_model_size(model):\n",
    "    \"\"\"모델 크기 측정 (파라미터 수, 메모리 사용량)\"\"\"\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    \n",
    "    size_mb = (param_size + buffer_size) / 1024**2\n",
    "    return {\n",
    "        'parameters': sum(p.numel() for p in model.parameters()),\n",
    "        'size_mb': size_mb\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_hardware_usage(model, test_loader):\n",
    "    \"\"\"Jetson Nano 하드웨어 사용량 측정\"\"\"\n",
    "    with jtop() as jetson:\n",
    "        stats = {\n",
    "            'cpu_usage': [],\n",
    "            'gpu_usage': [],\n",
    "            'memory_usage': [],\n",
    "            'power_usage': []\n",
    "        }\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, _ in test_loader:\n",
    "                _ = model(images)\n",
    "                \n",
    "                stats['cpu_usage'].append(jetson.cpu['cpu']['usage'])\n",
    "                stats['gpu_usage'].append(jetson.gpu['gpu']['usage'])\n",
    "                stats['memory_usage'].append(jetson.memory['used'] / jetson.memory['total'] * 100)\n",
    "                stats['power_usage'].append(jetson.power['power'])\n",
    "    \n",
    "    return {k: np.mean(v) for k, v in stats.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(results_df):\n",
    "    \"\"\"결과 시각화\"\"\"\n",
    "    # plt.style.use('seaborn') 대신 기본 스타일 사용\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    # 1. 모델 크기 vs 정확도\n",
    "    plt.subplot(231)\n",
    "    plt.scatter(results_df['Model_Size_MB'], results_df['Accuracy_%'], s=100)\n",
    "    for i, model in enumerate(results_df['Model']):\n",
    "        plt.annotate(model, (results_df['Model_Size_MB'][i], results_df['Accuracy_%'][i]))\n",
    "    plt.xlabel('Model Size (MB)')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Model Size vs Accuracy')\n",
    "    \n",
    "    # 2. 추론 시간 비교\n",
    "    plt.subplot(232)\n",
    "    bar1 = plt.bar(results_df['Model'], results_df['Avg_Inference_Time_ms'])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Inference Time (ms)')\n",
    "    plt.title('Average Inference Time')\n",
    "    \n",
    "    # 3. 메모리 사용량 비교\n",
    "    plt.subplot(233)\n",
    "    bar2 = plt.bar(results_df['Model'], results_df['Memory_Usage_MB'])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Memory Usage (MB)')\n",
    "    plt.title('Memory Usage')\n",
    "    \n",
    "    # 4. GFLOPs 비교\n",
    "    plt.subplot(234)\n",
    "    bar3 = plt.bar(results_df['Model'], results_df['GFLOPs'])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('GFLOPs')\n",
    "    plt.title('Computational Complexity')\n",
    "    \n",
    "    # 5. 파라미터 수 비교\n",
    "    plt.subplot(235)\n",
    "    bar4 = plt.bar(results_df['Model'], results_df['Parameters'] / 1e6)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Parameters (M)')\n",
    "    plt.title('Number of Parameters')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison_results.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # 모델 로드\n",
    "    basic_model, pruned_model, student_model = load_models()\n",
    "    \n",
    "    # 테스트 데이터셋 준비\n",
    "    test_dataset = CircleDataset('train/img', 'train/target')\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "    # 각 모델 평가\n",
    "    results = []\n",
    "    results.append(measure_model_metrics(basic_model, test_loader, device, \"Basic\"))\n",
    "    results.append(measure_model_metrics(pruned_model, test_loader, device, \"Pruned\"))\n",
    "    results.append(measure_model_metrics(student_model, test_loader, device, \"KD_Student\"))\n",
    "    \n",
    "    # 결과를 DataFrame으로 변환\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(\"\\nDetailed Results:\")\n",
    "    print(results_df)\n",
    "    \n",
    "    # 결과 시각화\n",
    "    plot_metrics(results_df)\n",
    "    \n",
    "    # 결과 저장\n",
    "    results_df.to_csv('results.csv', index=False)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Measuring metrics for Basic...\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghddp\\AppData\\Local\\Temp\\ipykernel_17188\\2359785757.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  basic_model.load_state_dict(torch.load('Basic_model.pth'))\n",
      "C:\\Users\\ghddp\\AppData\\Local\\Temp\\ipykernel_17188\\2359785757.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pruned_model.load_state_dict(torch.load('P_model.pth'))\n",
      "C:\\Users\\ghddp\\AppData\\Local\\Temp\\ipykernel_17188\\2359785757.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student_model.load_state_dict(torch.load('KD_model.pth'))\n",
      "c:\\Users\\ghddp\\Desktop\\embedded\\CircleDetection-1\\model.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  img = torch.load(img_path).float() / 255.0\n",
      "c:\\Users\\ghddp\\Desktop\\embedded\\CircleDetection-1\\model.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  target = torch.load(target_path).size(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Measuring metrics for Pruned...\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "\n",
      "Measuring metrics for KD_Student...\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "\n",
      "Detailed Results:\n",
      "        Model  Parameters  Model_Size_MB    GFLOPs  Avg_Inference_Time_ms  \\\n",
      "0       Basic      424961       1.624403  0.424738              15.309355   \n",
      "1      Pruned      424961       1.624403  0.424738              17.762222   \n",
      "2  KD_Student      106369       0.409132  0.112588               8.454459   \n",
      "\n",
      "   Inference_Time_Std_ms  Memory_Usage_MB  Accuracy_%  \n",
      "0               2.573946       378.855352        63.0  \n",
      "1               7.265150       379.025469        63.0  \n",
      "2               1.851926       379.203125        63.0  \n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "'seaborn' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ghddp\\anaconda3\\lib\\site-packages\\matplotlib\\style\\core.py:137\u001b[0m, in \u001b[0;36muse\u001b[1;34m(style)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     style \u001b[38;5;241m=\u001b[39m \u001b[43m_rc_params_in_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\ghddp\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:866\u001b[0m, in \u001b[0;36m_rc_params_in_file\u001b[1;34m(fname, transform, fail_on_error)\u001b[0m\n\u001b[0;32m    865\u001b[0m rc_temp \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 866\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_or_url(fname) \u001b[38;5;28;01mas\u001b[39;00m fd:\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ghddp\\anaconda3\\lib\\contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ghddp\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:843\u001b[0m, in \u001b[0;36m_open_file_or_url\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m    842\u001b[0m fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(fname)\n\u001b[1;32m--> 843\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'seaborn'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 26\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_df)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# 결과 시각화\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[43mplot_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 결과 저장\u001b[39;00m\n\u001b[0;32m     29\u001b[0m results_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m, in \u001b[0;36mplot_metrics\u001b[1;34m(results_df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_metrics\u001b[39m(results_df):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"결과 시각화\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseaborn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# 1. 모델 크기 vs 정확도\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ghddp\\anaconda3\\lib\\site-packages\\matplotlib\\style\\core.py:139\u001b[0m, in \u001b[0;36muse\u001b[1;34m(style)\u001b[0m\n\u001b[0;32m    137\u001b[0m         style \u001b[38;5;241m=\u001b[39m _rc_params_in_file(style)\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    140\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstyle\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is not a valid package style, path of style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile, URL of style file, or library style name (library \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    142\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyles are listed in `style.available`)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    143\u001b[0m filtered \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m style:  \u001b[38;5;66;03m# don't trigger RcParams.__getitem__('backend')\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: 'seaborn' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
