{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from thop import profile\n",
    "\n",
    "from model import CircleDataset\n",
    "from pruning import CircleNet_P\n",
    "from FP import CircleNet_FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pruning_models():\n",
    "    # Weight Pruning 모델\n",
    "    pruned_models_w = {}\n",
    "    for ratio in [25, 50, 75]:\n",
    "        model = CircleNet_P(pruning_ratio=ratio/100)\n",
    "        model.load_state_dict(torch.load(f'P_model_{ratio}.pth'))\n",
    "        pruned_models_w[f'Weight_Pruned_{ratio}'] = model\n",
    "    \n",
    "    # Filter Pruning 모델\n",
    "    pruned_models_f = {}\n",
    "    for ratio in [25, 50, 75]:\n",
    "        base_model = CircleNet_FP(pruning_ratio=ratio/100)\n",
    "        pruned_model = base_model.prune_filters()  # pruning 적용\n",
    "        pruned_model.load_state_dict(torch.load(f'FP_model_{ratio}.pth'))\n",
    "        pruned_models_f[f'Filter_Pruned_{ratio}'] = pruned_model\n",
    "        \n",
    "    return {**pruned_models_w, **pruned_models_f}\n",
    "\n",
    "def calculate_flops(model, input_size=(1, 1, 416, 416)):\n",
    "    input = torch.randn(input_size)\n",
    "    flops, params = profile(model, inputs=(input, ))\n",
    "    return flops, params\n",
    "\n",
    "def measure_model_metrics(model, test_loader, device, model_name):\n",
    "    print(f\"\\nMeasuring metrics for {model_name}...\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 모델 크기 및 파라미터\n",
    "    param_count = sum(p.numel() for p in model.parameters())\n",
    "    torch.save(model.state_dict(), 'temp.pth')\n",
    "    model_size = os.path.getsize('temp.pth') / (1024 * 1024)  # MB\n",
    "    os.remove('temp.pth')\n",
    "    \n",
    "    # FLOPs 계산\n",
    "    try:\n",
    "        flops, _ = calculate_flops(model)\n",
    "    except Exception as e:\n",
    "        print(f\"FLOPs calculation failed: {e}\")\n",
    "        flops = 0\n",
    "    \n",
    "    # 추론 성능 측정\n",
    "    model.eval()\n",
    "    inference_times = []\n",
    "    memory_usage = []\n",
    "    accuracy = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in test_loader:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            memory_usage.append(psutil.Process().memory_info().rss / 1024**2)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            outputs = model(images)\n",
    "            inference_times.append((time.time() - start_time) * 1000)\n",
    "            \n",
    "            pred = outputs.round()\n",
    "            acc = (torch.abs(pred - targets) <= 1).float().mean().item()\n",
    "            accuracy.append(acc)\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Parameters': param_count,\n",
    "        'Model_Size_MB': model_size,\n",
    "        'GFLOPs': flops / 1e9,\n",
    "        'Avg_Inference_Time_ms': np.mean(inference_times),\n",
    "        'Inference_Time_Std_ms': np.std(inference_times),\n",
    "        'Memory_Usage_MB': np.mean(memory_usage),\n",
    "        'Accuracy_%': np.mean(accuracy) * 100\n",
    "    }\n",
    "\n",
    "def plot_pruning_metrics(results_df):\n",
    "    # seaborn 스타일 대신 기본 스타일 사용\n",
    "    plt.style.use('default')\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    \n",
    "    ratios = ['25', '50', '75']\n",
    "    colors = {'Weight_Pruned': 'blue', 'Filter_Pruned': 'red'}\n",
    "    \n",
    "    # 1. Model Size\n",
    "    plt.subplot(231)\n",
    "    for method in ['Weight_Pruned', 'Filter_Pruned']:\n",
    "        try:\n",
    "            sizes = [results_df[results_df['Model'] == f'{method}_{r}']['Model_Size_MB'].values[0] for r in ratios]\n",
    "            plt.plot(ratios, sizes, marker='o', label=method, color=colors[method])\n",
    "        except:\n",
    "            continue\n",
    "    plt.xlabel('Pruning Ratio (%)')\n",
    "    plt.ylabel('Model Size (MB)')\n",
    "    plt.title('Model Size vs Pruning Ratio')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 2. Inference Time\n",
    "    plt.subplot(232)\n",
    "    for method in ['Weight_Pruned', 'Filter_Pruned']:\n",
    "        try:\n",
    "            times = [results_df[results_df['Model'] == f'{method}_{r}']['Avg_Inference_Time_ms'].values[0] for r in ratios]\n",
    "            plt.plot(ratios, times, marker='o', label=method, color=colors[method])\n",
    "        except:\n",
    "            continue\n",
    "    plt.xlabel('Pruning Ratio (%)')\n",
    "    plt.ylabel('Inference Time (ms)')\n",
    "    plt.title('Inference Time vs Pruning Ratio')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 3. Memory Usage\n",
    "    plt.subplot(233)\n",
    "    for method in ['Weight_Pruned', 'Filter_Pruned']:\n",
    "        try:\n",
    "            memory = [results_df[results_df['Model'] == f'{method}_{r}']['Memory_Usage_MB'].values[0] for r in ratios]\n",
    "            plt.plot(ratios, memory, marker='o', label=method, color=colors[method])\n",
    "        except:\n",
    "            continue\n",
    "    plt.xlabel('Pruning Ratio (%)')\n",
    "    plt.ylabel('Memory Usage (MB)')\n",
    "    plt.title('Memory Usage vs Pruning Ratio')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 4. GFLOPs\n",
    "    plt.subplot(234)\n",
    "    for method in ['Weight_Pruned', 'Filter_Pruned']:\n",
    "        try:\n",
    "            gflops = [results_df[results_df['Model'] == f'{method}_{r}']['GFLOPs'].values[0] for r in ratios]\n",
    "            plt.plot(ratios, gflops, marker='o', label=method, color=colors[method])\n",
    "        except:\n",
    "            continue\n",
    "    plt.xlabel('Pruning Ratio (%)')\n",
    "    plt.ylabel('GFLOPs')\n",
    "    plt.title('Computational Complexity vs Pruning Ratio')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 5. Accuracy\n",
    "    plt.subplot(235)\n",
    "    for method in ['Weight_Pruned', 'Filter_Pruned']:\n",
    "        try:\n",
    "            acc = [results_df[results_df['Model'] == f'{method}_{r}']['Accuracy_%'].values[0] for r in ratios]\n",
    "            plt.plot(ratios, acc, marker='o', label=method, color=colors[method])\n",
    "        except:\n",
    "            continue\n",
    "    plt.xlabel('Pruning Ratio (%)')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Accuracy vs Pruning Ratio')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pruning_comparison_results.png')\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    try:\n",
    "        # 모델 로드\n",
    "        pruned_models = load_pruning_models()\n",
    "        \n",
    "        # 테스트 데이터셋 준비\n",
    "        test_dataset = CircleDataset('train/img', 'train/target')\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "        \n",
    "        # 각 모델 평가\n",
    "        results = []\n",
    "        for name, model in pruned_models.items():\n",
    "            try:\n",
    "                result = measure_model_metrics(model, test_loader, device, name)\n",
    "                results.append(result)\n",
    "                print(f\"Successfully evaluated {name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error evaluating {name}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        # 결과를 DataFrame으로 변환\n",
    "        results_df = pd.DataFrame(results)\n",
    "        \n",
    "        # 결과 출력\n",
    "        print(\"\\nDetailed Results:\")\n",
    "        print(results_df)\n",
    "        \n",
    "        # 결과 시각화\n",
    "        try:\n",
    "            plot_pruning_metrics(results_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting results: {str(e)}\")\n",
    "        \n",
    "        # 결과 저장\n",
    "        results_df.to_csv('pruning_results.csv', index=False)\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading models: {str(e)}\")\n",
    "        print(\"Make sure you have trained all pruning models first!\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Measuring metrics for Weight_Pruned_25...\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghddp\\AppData\\Local\\Temp\\ipykernel_33328\\452463670.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'P_model_{ratio}.pth'))\n",
      "C:\\Users\\ghddp\\AppData\\Local\\Temp\\ipykernel_33328\\452463670.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pruned_model.load_state_dict(torch.load(f'FP_model_{ratio}.pth'))\n",
      "c:\\Users\\ghddp\\Desktop\\embedded\\CircleDetection-1\\model.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  img = torch.load(img_path).float() / 255.0\n",
      "c:\\Users\\ghddp\\Desktop\\embedded\\CircleDetection-1\\model.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  target = torch.load(target_path).size(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Measuring metrics for Weight_Pruned_50...\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "\n",
      "Measuring metrics for Weight_Pruned_75...\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "\n",
      "Measuring metrics for Filter_Pruned_25...\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "\n",
      "Measuring metrics for Filter_Pruned_50...\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "\n",
      "Measuring metrics for Filter_Pruned_75...\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "\n",
      "Detailed Results:\n",
      "              Model  Parameters  Model_Size_MB    GFLOPs  \\\n",
      "0  Weight_Pruned_25      424961       1.624403  0.424738   \n",
      "1  Weight_Pruned_50      424961       1.624403  0.424738   \n",
      "2  Weight_Pruned_75      424961       1.624403  0.424738   \n",
      "3  Filter_Pruned_25      314465       1.219435  0.243793   \n",
      "4  Filter_Pruned_50      206849       0.814405  0.112689   \n",
      "5  Filter_Pruned_75      102113       0.409437  0.031424   \n",
      "\n",
      "   Avg_Inference_Time_ms  Inference_Time_Std_ms  Memory_Usage_MB  Accuracy_%  \n",
      "0              38.514426              11.873873       374.609375        63.0  \n",
      "1              18.218749               3.062362       374.725859        63.0  \n",
      "2              18.208861               2.942349       374.798750        63.0  \n",
      "3              14.254780               2.340787       374.771758        63.0  \n",
      "4               8.636429               0.953543       374.781250        63.0  \n",
      "5               5.535588               0.702873       374.753359        63.0  \n",
      "Error loading models: 'seaborn' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)\n",
      "Make sure you have trained all pruning models first!\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
